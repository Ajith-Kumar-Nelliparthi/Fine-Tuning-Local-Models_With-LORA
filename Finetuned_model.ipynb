{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7mL_4WY2E-Bi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n",
        "\n",
        "from peft import PeftModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxOc25OWPyfY",
        "outputId": "fa70b11e-ab2f-40d9-effa-7dc25e2b9112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rmDhpsRnPrkQ"
      },
      "outputs": [],
      "source": [
        "# !pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTqFPqCbPu-3",
        "outputId": "1ae789b7-e4ad-4141-f5f8-1daf53dbcaf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "c371a6ae7d074d55a2ff408f085ed0c4",
            "87661d381c9c4f008589ff869bf9cc17",
            "898670a5b72441549be85892e74d4322",
            "78b8849c02374adf84f3b90e48838982",
            "0a0a26423b084beb82f111df4138785f",
            "29310b1a8ea54749ac536b7e61f2bb9b",
            "d76f06582c67474ea3ff41e9cc5637c1",
            "c8218beb204f4f1eb6734892b6da0681",
            "68b56463f4854e539f082f5d9990ea14",
            "f70b29d051054168b8ae24ec54ec2cb5",
            "26dbe2c3f5da4d3abaafe40c074e25a5",
            "94f2754246dd4365ac087477c3f1e510",
            "cf1a80f666f34c84bba0e11c513d9fcc",
            "05f4964bb74240fca9d0820fd7a173c3",
            "1d24cac4ce12425cb6d1d27f2de52be9",
            "007b2a9f44f34ae0b8ceaf3d388d9f9d",
            "5711b75124434658a40179e792bef1ab",
            "6959aaec432946ecb0a4937c3471c045",
            "c77973cb7517463fbf3e875a0c503ea5",
            "5566b010ee6b4eff8e550aec4d732724",
            "472715b382ec4d60a79ca3084b11c801",
            "c1afca87f84446efbb520fdcecaa1484"
          ]
        },
        "id": "5lgnFlSPFAoU",
        "outputId": "40960d5f-0902-47a7-ed2b-36e5cc80e952"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c371a6ae7d074d55a2ff408f085ed0c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94f2754246dd4365ac087477c3f1e510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
        "adapter_path = \"/content/drive/MyDrive/tinyllama-lora-tuned-adapter-math\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_quant_type = 'nf4',\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config = bnb_config,\n",
        "    device_map = 'auto',\n",
        "    trust_remote_code = True\n",
        ").eval()\n",
        "\n",
        "tmp_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config = bnb_config,\n",
        "    device_map = 'auto',\n",
        "    trust_remote_code = True\n",
        ")\n",
        "\n",
        "tuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\n",
        "tuned_model = tuned_model.merge_and_unload().eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "02u_A85dFAq8"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "    texts = [\n",
        "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
        "        for inst, out in zip(batch['question'], batch['answer'])\n",
        "    ]\n",
        "\n",
        "    tokens = tokenizer(\n",
        "        texts,\n",
        "        padding = 'max_length',\n",
        "        truncation = True,\n",
        "        max_length = 256,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "\n",
        "    tokens['labels'] = tokens['input_ids'].clone()\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "fadc00c25a814cac8d0e9eb5222b3390",
            "e1f8d270a4034f78802285dd4f64203c",
            "cc98475d9c04460799fe2a24ce87d389",
            "24bb213c3c3149f981ab09b8c5ba7a88",
            "0aa592a1ff3e4ee9a7524bd830ed504b",
            "8ccd71b5f0564ec8a6c607b977f0c6e3",
            "7ce5e6b5cc11490a9f5a3f97ce01a8e8",
            "d09d73657ab54384939cdfb757851c94",
            "c3e889f316cc48ec81fb167cff8e3184",
            "040edd46f18b458797830c96c37bff41",
            "a1f358cb67b1480985e89d61c1b0abab",
            "cc19fb0c89c04157b36b81c57b77afed",
            "8fa48dc2351d480aa5f1923ef9c29e32",
            "d6be5aa210944362a8aebf6e18bbe10f",
            "a0d2a33760da4ed79a44fb9702d7bcc2",
            "6b8a6dbfe69e443ea048b77268d69b0c",
            "ddaeb091ec6a433398bc8aebe36f16c5",
            "f65bc718a5ed4ea9b941673fc2e570a9",
            "b841091b5f9c45a2a7f75bd5604abf93",
            "9fa57074adf54cab977319bc996f5603",
            "9da84aed919c45d6b4bc7c3e55b418b7",
            "aea2bb0e94004e12963421fb4dc02c2a",
            "1743ce21afbb47dc8089028b5ea0fb79",
            "1a367d7de69542f9b2cfdca788a12828",
            "3957e6e4473f4fa88535e1f2f423b465",
            "cf085654ffad47c491273b3c50fb6dd0",
            "f528e322eced47ed802632f8cd8edc43",
            "348fedadd9004fc993f73eb0369f08fb",
            "8b980be8c4034f27a93c47eed324902c",
            "1fd76be2d8344e778eb70eec1cdd0a5d",
            "07fe4b6af2694514ba69c68a2e427ad2",
            "591d9bff20d048c7ac30f6f76af4712f",
            "73ef1a66cdfd42b4a85a2c927cf97952",
            "d527ca9effe44341aa73536c1ff3efde",
            "4cca773e9aaf436aa0e3fd4531592d1a",
            "2ca1dd2029574493b691d85b7845abcb",
            "843b0f6d61e7450f9d76b10511ef8f71",
            "b5cc420b8a6048aabe86452cff3c20a1",
            "ee66105b93c34bd79b8d8831a6260919",
            "ab9e736cc8ba4eb1a4a33a744f89db9f",
            "468571e0cdee4c3bbf2f588d724e3e84",
            "5c03e59ccf124e73b2bc02b59c7a12fd",
            "c2071e9f958f46ed8e14831853ec1ab1",
            "148da03b7279495d94dd98a6d9520a53",
            "8cbe0e598f00462cb836d4832b47fe6b",
            "090c5d40a0b64df2a6b2b08cf6f43d50",
            "d142870586f744e7925585fe629919d3",
            "3f63f443db16409db36ed26ebcdcfc3f",
            "fa00b28e03d9469a85d40f35911b3342",
            "72d2545193654f6aa049bee75eea305d",
            "4b2af252c40a45fd8da1f9287a60ee5c",
            "e1d5ae3cbfe84ff4ab7ae2e6ff6a9918",
            "69ffb63cace6460a9592afc3098933d1",
            "8d1d2aa14e774c0d9c170db1f87dc610",
            "d132e2ab44d94af5b170ad725d4cd53a",
            "6d671f352fdf4effb150a591b6722a46",
            "db06e13d33154879b897b501d4dbc66b",
            "2e57f327c2424c09a2c27d15b8aae162",
            "f6846e62caf14feaab5c8ba1322063d1",
            "65342c0f155b4f4aa5a8489d07b868e8",
            "a77b1918f985471eb5aaa8fa77a3efba",
            "43a1554426a44230bee6d178333b7e62",
            "14ff8cc5053c47118601e69abe2c8b23",
            "b1a2bf891df645f0aadef9905a50a83e",
            "8c743485e4514f08b237cd5ad82fcbd8",
            "388d7551df5e434085b6562921325785"
          ]
        },
        "id": "kPaqOxIiFAv9",
        "outputId": "3b77368f-11c9-4180-95c3-e9d938e8e5cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fadc00c25a814cac8d0e9eb5222b3390",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc19fb0c89c04157b36b81c57b77afed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1743ce21afbb47dc8089028b5ea0fb79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d527ca9effe44341aa73536c1ff3efde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cbe0e598f00462cb836d4832b47fe6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d671f352fdf4effb150a591b6722a46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[:20]')\n",
        "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
        "eval_ds = eval_ds.with_format('torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MwKyAaKJFAyi"
      },
      "outputs": [],
      "source": [
        "eval_loader = DataLoader(\n",
        "    eval_ds,\n",
        "    batch_size = 8,\n",
        "    collate_fn = default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YAKiv06hFA1L"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_perplexity(model):\n",
        "    losses = []\n",
        "\n",
        "    for batch in eval_loader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "        loss = model(**batch).loss\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return math.exp(sum(losses) / len(losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-qQGYkzFA37",
        "outputId": "476bab47-cc43-4001-85ee-5037a89034ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base Model Perplexity: 139.67\n",
            "Tuned Model Perplexity: 1.16\n"
          ]
        }
      ],
      "source": [
        "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
        "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "aa4fb4c741274880afcc0d4096f6582b",
            "c902560d1eeb48238548988f6deb0673",
            "7c6c1bb261db4b95942dd3cc992eba1f",
            "24283923cdd74465a0509b7c28badfe7",
            "afd1569a7ef54b47a0849a89c4be7d6c",
            "c2591b8d9d554dea9dde7c28a5813591",
            "7f0f0eec2cd14522b9b89173fb05ad3a",
            "0940df7f12bc47cdba6005a1c6d71413",
            "c8c0b5e47ee74503b7f5166005097532",
            "d48097326ad54a8f85d53f4d2ef6dae7",
            "d490aa7f76344597a7b0721b411e6158",
            "914cd177b47143b6bbfc2f774808168a",
            "81b5906787604e85a81ca8083306b6ad",
            "7422ae4fc13f41f3a518efc610a62e12",
            "2f095713280e44d1855f98621817d667",
            "3d3020849e5b4ca5a7437235582647bc",
            "597fe41ac00341a5b661336d2ed66e16",
            "989d1b1ee083446cbf1a277881fa4396",
            "0f7e7b4998e043e1b46bbaa947915432",
            "d3851df5da9344c9a921822af44b7978",
            "d048d45be84d469f9c801b8fd65b2bfd",
            "e296b42b99a6437ebac9b1dc1d38a0ae",
            "8d741a5b44404d459666ca8cfcbcd88a",
            "4c938306e6bd4bbc837eb9d28a17d75d",
            "173b82f7d06d45678af2e99402ffb21c",
            "0e8eba1bf15f401d84cf4acdaf87c299",
            "b31fe029e4f4495d8e352dbab750457d",
            "7eadf69e4b504dca8dcd20f323c391ae",
            "9998d1919ab6437baf1594e23981bcd3",
            "1c50962f1bf945739e01ed61243c48bf",
            "fe0e7fef070b4bdf9b941dcb88b424ec",
            "1f83d36521524995acfe0ee24bc1d957",
            "7d4613f8218c4a50a7b030418947ca82",
            "fb5d71b5fa574d9f8330635c6dd47afd",
            "dab45a65756a4f9dbf2700c4e246f72c",
            "1117b33cb4d8468187caee73655d50b3",
            "1b73ea97ea2846f6a998f28b8044ff65",
            "56200a0434094eff9d5ea004db2364e5",
            "822f1e3ecfa24e778a7b21fddfa22c73",
            "a72fb63e3ee448b9aa772e5ed61bb996",
            "01e870a374e64ccb8ab8f4dc33066364",
            "77346d78758b465fab854a236143bb86",
            "9cb538d42a9541d59ba3bf46cdbd1cac",
            "dd1cb34de4824fcbb4ff890f98bb8f9e",
            "541b2504351a411182236593cfa9169b",
            "dd5a76c74d1542378b879df24cf9fc5b",
            "56fc2d0ef59a45d4befc21b8e4d6f1fd",
            "7a7149a0b237488a9f265ffbcfbb8b79",
            "51e2223324644305b772b659599b72f5",
            "9545334459084fb880cc78445d94eb94",
            "987835f3d2444f719a0857fb3df1029a",
            "597d099847cc448f80ac72205d77c2bd",
            "c3c141424a764831bf2adacd7df681e9",
            "e5e9bc15a1fa45c198d5ded86832bedb",
            "5467625e20f24f2b867702153b4a3b76"
          ]
        },
        "id": "coVudy8UFA6a",
        "outputId": "88eb67ee-8269-4f2f-e6e8-1c0b179aa239"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa4fb4c741274880afcc0d4096f6582b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "914cd177b47143b6bbfc2f774808168a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d741a5b44404d459666ca8cfcbcd88a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5d71b5fa574d9f8330635c6dd47afd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "541b2504351a411182236593cfa9169b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "raw_data = load_dataset('gsm8k', 'main', split='train[:20]')\n",
        "refs = raw_data['answer']\n",
        "\n",
        "\n",
        "def generate(model, instruction):\n",
        "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(token_ids, max_new_tokens=256)\n",
        "\n",
        "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0v5VKx3QFA9L",
        "outputId": "20b6a0ab-d50a-418c-fb7d-a8c696c51b17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data['question'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgeATZ_pFBAM",
        "outputId": "69801456-5764-4c91-d43e-fd1a7671f52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Instruction:\n",
            "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
            "### Response:\n",
            "The answer is $60.\n"
          ]
        }
      ],
      "source": [
        "print(generate(base_model, raw_data['question'][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVEt_0dbFBCK",
        "outputId": "eadee298-859c-4d36-f8e2-188c08ee6315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Instruction:\n",
            "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
            "### Response:\n",
            "Weng earns 12/60 = $<<12/60=2>>24 an hour.\n",
            "50 minutes of babysitting = 50*24 = $<<50*24=1200>>1200\n",
            "She earns $1200/year = 1200*12 = $<<1200*12=14400>>14,400\n",
            "Her fee for yesterday is 14,400-24 = $<<14400-2400=1200>>1200\n",
            "#### 1200\n"
          ]
        }
      ],
      "source": [
        "print(generate(tuned_model, raw_data['question'][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4--XpboDFBE4",
        "outputId": "327e3bb1-5cbd-4644-a21c-49bfec482a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
            "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
            "#### 10\n"
          ]
        }
      ],
      "source": [
        "print(refs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8b95f818c22e439aa556da7127d235ed",
            "ffd4fb7d42414d408a54b689fd509e90",
            "991bc3bb36534310b77e85128a4b1d31",
            "e88abe34401b4559b5d42a20c50be9e4",
            "b151d28a5d9f48a78448db8d22d5c0d3",
            "8b6d78c1fa084f00b6d108d098ca1f58",
            "4bf406ab1d054fac8c0043e35597c97c",
            "78078fa261f34bddafb8113b41bfb2b1",
            "dfd7a8334e8e4873ba02a1e30ce55f5d",
            "f60c43511b684f90be78591c92dc2a6e",
            "f59773c6ec0946118a684046aa3269b9"
          ]
        },
        "id": "JKVigD9MFBHS",
        "outputId": "15142575-0ab0-495c-badb-40c4f7c38362"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b95f818c22e439aa556da7127d235ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[200:300]')\n",
        "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
        "eval_ds = eval_ds.with_format('torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NMmGY4JhFBJy"
      },
      "outputs": [],
      "source": [
        "eval_loader = DataLoader(\n",
        "    eval_ds,\n",
        "    batch_size = 8,\n",
        "    collate_fn = default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oK0WtamFBMV",
        "outputId": "a1807ea7-d125-4e58-835a-77904a66b52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base Model Perplexity: 229.65\n",
            "Tuned Model Perplexity: 4.80\n"
          ]
        }
      ],
      "source": [
        "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
        "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VRnXKbb4FBPC"
      },
      "outputs": [],
      "source": [
        "raw_data = load_dataset('gsm8k', 'main', split='train[200:300]')\n",
        "refs = raw_data['answer']\n",
        "\n",
        "\n",
        "def generate(model, instruction):\n",
        "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(token_ids, max_new_tokens=256)\n",
        "\n",
        "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SksvcG2BHEZo",
        "outputId": "8a9ffbaf-f5d3-40bc-c38d-d73431325f0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "raw_data['question'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi6MPzc9HIQB",
        "outputId": "3fa1e7e1-a0b3-4c92-a3aa-73f1b71d3f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Instruction:\n",
            "Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n",
            "### Response:\n",
            "Sansa earns $100 per day, which means she earns $300 per week, and $1,200 per month, and $5,000 per year.\n"
          ]
        }
      ],
      "source": [
        "print(generate(base_model, raw_data['question'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNMUKhJ0HJxo",
        "outputId": "f85f734d-e999-41ec-ec74-50cdaefc5573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Instruction:\n",
            "Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n",
            "### Response:\n",
            "Sansa earns each portrait a $5 size depending on its size, so she earns 3 portraits $5 each = $<<3*5=15>>15 each.\n",
            "She sells 5 x 16-inch portraits for $15 each because 5 portraits per day is the price for a 16-inch portrait, and she sold them all in three days.\n",
            "#### 15\n"
          ]
        }
      ],
      "source": [
        "print(generate(tuned_model, raw_data['question'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKFDScM-HMTw",
        "outputId": "00900ebc-5d67-4fce-ae0b-eec388769210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sansa earns $5 x 3 = $<<5*3=15>>15 every day by selling three 8-inch portraits.\n",
            "The price of the 16-inch portrait is $5 x 2 = $<<5*2=10>>10 each.\n",
            "So, she earns $10 x 5 = $<<10*5=50>>50 every day by selling five 16-inch portraits.\n",
            "Her total earnings is $50 + $15 = $<<50+15=65>>65 every day.\n",
            "Therefore, the total amount she earns after 3 days is $65 x 3 = $<<65*3=195>>195.\n",
            "#### 195\n"
          ]
        }
      ],
      "source": [
        "print(refs[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
